# RAG-MAG

Multimodal RAG system that processes PDF manuals and answers questions using both text and images.

## Quick Start

```bash
# 1. Setup
cp env.example .env  # Configure with your API keys
pip install -r requirements.txt

# 2. Parse documents (stores in Qdrant Cloud)
make parse  # or: python src/parse.py

# 3. Choose your interface:

# Option A: Streamlit UI (interactive web app)
make run    # or: streamlit run src/app.py

# Option B: FastAPI REST API (for programmatic access)
make api    # or: cd src && uvicorn api.main:app --reload
```

**Architecture:**
- **Vector Database**: Qdrant Cloud (for embeddings + images)
- **Image Storage**: Base64 encoded in Qdrant
- **LLM**: OpenAI or Gemini (configurable)
- **Parser**: LlamaParse for multimodal PDF extraction

## Table of Contents

- [Configuration](#configuration)
- [Document Ingestion Workflow](#document-ingestion-workflow)
- [Ingestion Architecture](#ingestion-architecture)
- [FastAPI Backend](#fastapi-backend)
- [Project Structure](#project-structure)
- [Development](#development)
- [Testing](#testing)
- [Tech Stack](#tech-stack)
- [Next Steps](#next-steps)

---

## Configuration

All configuration is centralized in `.env` file:

```bash
cp env.example .env  # Then edit with your values
```

### Required Settings

```bash
# API Keys
OPENAI_API_KEY=your_key_here
GEMINI_API_KEY=your_key_here
LLAMAPARSE_API_KEY=your_key_here

# LLM Provider
LLM_PROVIDER=gemini  # or openai

# Vector Database (Qdrant Cloud - pre-configured)
VECTOR_DB_TYPE=qdrant
QDRANT_URL=https://your-cluster.gcp.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_key

# Image Storage
IMAGE_STORAGE_FORMAT=base64  # Images stored in Qdrant
```

### Optional Settings

See `env.example` for all available configuration options including:
- LlamaParse settings (model, region, OCR options)
- LLM model selection (OpenAI/Gemini)
- RAG parameters (chunk size, similarity threshold)
- Directory paths

---

## Document Ingestion Workflow

### Initial Setup

```bash
# Put your PDFs in data/
cp /path/to/manuals/*.pdf data/

# Parse and index to Qdrant Cloud
make parse
```

**What this does:**
- âœ… Parses ALL PDFs in `data/` with LlamaParse
- âœ… Extracts text and page images
- âœ… Converts images to base64
- âœ… Stores vectors and images in Qdrant Cloud
- âœ… Assigns UUID to each document for tracking

**Output:**
```
ğŸ“„ Found 25 PDF file(s)
ğŸ“ Parsing documents...
   [1/25] Parsing manual1.pdf...
       âœ… Extracted 42 pages
   ...
ğŸ“Š Summary:
   Documents indexed: 25
   Total pages: 1,247
   Stored in Qdrant Cloud
```

### Add More Documents

**Via API:**
```bash
# Upload via REST API
curl -X POST "http://localhost:8000/documents" \
  -F "file=@new-manual.pdf"
```

**Via Batch Script:**
```bash
# Add new PDFs to data/
cp /path/to/more/*.pdf data/

# Add to existing index (preserves existing documents)
make add-batch
```

---

## Ingestion Architecture

### Overview

The system includes a dedicated document management module (`src/ingestion/`) that provides CRUD operations with Qdrant Cloud storage.

### Key Features

âœ… **Qdrant Cloud Storage**: Vectors and images stored in managed cloud database  
âœ… **Base64 Images**: Images encoded and stored directly in Qdrant  
âœ… **Document Tracking**: Proper SOURCE relationships enable document-level operations  
âœ… **CRUD Operations**: Add, delete, update, and list documents programmatically  
âœ… **UUID System**: Each document gets a unique identifier for tracking  
âœ… **Multi-Worker Ready**: Qdrant supports concurrent access from multiple API workers  

### Core Components

#### 1. **parser.py** - LlamaParse Wrapper
- Wraps LlamaParse with SOURCE relationship configuration
- Extracts text and page screenshots from PDFs
- Encodes images to base64 for Qdrant storage
- Attaches metadata: document_id, filename, page_number, image_b64

#### 2. **index_manager.py** - Index Lifecycle
- Manages connection to Qdrant Cloud
- Singleton pattern for efficient index access
- Configures LLM and embedding models
- Supports both local and cloud vector stores

#### 3. **document_manager.py** - CRUD Operations
- `add_document(pdf_path, doc_id=None)` - Add PDF to Qdrant
- `delete_document(doc_id)` - Remove document from Qdrant
- `update_document(doc_id, new_pdf_path)` - Replace document
- `list_documents()` - Get all indexed documents
- `get_document_info(doc_id)` - Detailed document information

#### 4. **vector_store.py** - Vector Database Management
- Handles Qdrant Cloud connection
- Manages vector store configuration
- Supports multiple backend options (Qdrant, local, etc.)

### Usage Examples

**CLI (Batch Processing):**
```bash
make parse        # Parse and upload to Qdrant Cloud
make add-batch    # Add more documents (preserves existing)
```

**Python (Programmatic):**
```python
from ingestion import add_document, delete_document, list_documents

# Add a document (uploads to Qdrant Cloud)
result = await add_document("manual.pdf")
doc_id = result['document_id']

# List all documents
docs = list_documents()
for doc_id, info in docs.items():
    print(f"{doc_id}: {info['metadata']['filename']}")

# Delete document (removes from Qdrant)
delete_document(doc_id)
```

**Testing:**
```bash
python scripts/test_ingestion.py  # Test CRUD operations
```

### Technical Implementation

**SOURCE Relationships:**
```python
from llama_index.core.schema import NodeRelationship, RelatedNodeInfo

# Enable document tracking and deletion
node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(node_id=doc_id)
```

This enables proper document tracking in Qdrant and allows deletion by document ID.

**Base64 Image Storage:**
```python
# Images encoded and stored in node metadata
node.metadata["image_b64"] = base64.b64encode(image_data).decode('utf-8')
```

Images are stored directly in Qdrant alongside text embeddings for atomic operations.

### Scalability

With Qdrant Cloud:
- âœ… **Multi-Process**: Multiple API workers can access the same index
- âœ… **Automatic Persistence**: Changes are immediately synced to cloud
- âœ… **Concurrent Access**: Thread-safe operations
- âœ… **Horizontal Scaling**: Add more API workers as needed

### API Integration

The ingestion module works seamlessly with FastAPI:

```python
from fastapi import FastAPI, UploadFile, BackgroundTasks
from ingestion import add_document, delete_document

app = FastAPI()

@app.post("/documents")
async def upload(file: UploadFile, bg: BackgroundTasks):
    temp_path = f"/tmp/{file.filename}"
    with open(temp_path, "wb") as f:
        f.write(await file.read())
    bg.add_task(add_document, temp_path)
    return {"status": "processing"}

@app.delete("/documents/{doc_id}")
def delete(doc_id: str):
    return delete_document(doc_id)
```

---

## FastAPI Backend

### Overview

The FastAPI backend provides REST API endpoints for programmatic access to the RAG system.

**Features:**
- âœ… Document upload, list, retrieve, update, delete (CRUD)
- âœ… Multimodal query endpoint (text + images)
- âœ… Image serving for page screenshots
- âœ… Background task processing for uploads
- âœ… Auto-generated API documentation (Swagger UI)
- âœ… Async/await support for efficiency

### Quick Start

```bash
# Start API server
make api

# Access documentation
# - Swagger UI: http://localhost:8000/docs
# - ReDoc: http://localhost:8000/redoc
# - Health: http://localhost:8000/health
```

### API Endpoints

#### Document Management

**Upload Document**
```bash
curl -X POST "http://localhost:8000/documents" \
  -F "file=@manual.pdf"
```

**List Documents**
```bash
curl "http://localhost:8000/documents"
```

**Get Document Details**
```bash
curl "http://localhost:8000/documents/{doc_id}"
```

**Delete Document**
```bash
curl -X DELETE "http://localhost:8000/documents/{doc_id}"
```

**Update Document**
```bash
curl -X PUT "http://localhost:8000/documents/{doc_id}" \
  -F "file=@new_manual.pdf"
```

#### Query

**Query Documents**
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How to install?",
    "similarity_top_k": 3,
    "include_images": true
  }'
```

#### Images

**Get Page Image**
```bash
curl "http://localhost:8000/images/{doc_id}/{page_number}" \
  --output page.jpg
```

### Python Client Example

```python
import requests

API_URL = "http://localhost:8000"

# Upload document
with open("manual.pdf", "rb") as f:
    response = requests.post(
        f"{API_URL}/documents",
        files={"file": f}
    )
    doc_id = response.json()["document_id"]

# Query
response = requests.post(
    f"{API_URL}/query",
    json={
        "query": "How to install?",
        "similarity_top_k": 3
    }
)
print(response.json()["answer"])

# List documents
response = requests.get(f"{API_URL}/documents")
print(response.json())

# Delete document
requests.delete(f"{API_URL}/documents/{doc_id}")
```

### Testing the API

```bash
# Run example Python script
python examples/api_usage.py

# Or use the shell script
./examples/test_api.sh
```

### Production Deployment

```bash
# Multi-worker mode
make api-prod

# Or manually with 4 workers
cd src && uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

For detailed API documentation, see [`src/api/README.md`](src/api/README.md).

---

## Project Structure

```
Mag-/
â”œâ”€â”€ src/                     # Application code
â”‚   â”œâ”€â”€ config.py           # Centralized configuration
â”‚   â”œâ”€â”€ app.py              # Streamlit web app (query interface)
â”‚   â”œâ”€â”€ parse.py            # CLI batch document parser
â”‚   â”œâ”€â”€ add_pdfs_batch.py   # Add PDFs to existing index
â”‚   â”œâ”€â”€ api/                # FastAPI backend (NEW!)
â”‚   â”‚   â”œâ”€â”€ __init__.py     # API module exports
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI app and configuration
â”‚   â”‚   â”œâ”€â”€ models.py       # Pydantic request/response models
â”‚   â”‚   â”œâ”€â”€ dependencies.py # Shared dependencies
â”‚   â”‚   â”œâ”€â”€ routes/         # API route modules
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py # Document CRUD endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py    # Query endpoint
â”‚   â”‚   â”‚   â””â”€â”€ images.py   # Image serving endpoints
â”‚   â”‚   â””â”€â”€ README.md       # API documentation
â”‚   â””â”€â”€ ingestion/          # Document management module
â”‚       â”œâ”€â”€ __init__.py     # Module exports
â”‚       â”œâ”€â”€ parser.py       # LlamaParse wrapper
â”‚       â”œâ”€â”€ index_manager.py # Index lifecycle
â”‚       â”œâ”€â”€ document_manager.py # CRUD operations
â”‚       â””â”€â”€ README.md       # Module documentation
â”œâ”€â”€ examples/               # Usage examples (NEW!)
â”‚   â”œâ”€â”€ api_usage.py        # Python API client example
â”‚   â””â”€â”€ test_api.sh         # Shell script for testing API
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_ingestion.py   # Ingestion test suite
â”‚   â”œâ”€â”€ install-hooks.sh    # Git hook installer
â”‚   â””â”€â”€ clean.sh            # Cleanup utility
â”œâ”€â”€ tests/                  # Test suite (43+ tests)
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_parse.py
â”‚   â”œâ”€â”€ test_app.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                   # Input PDFs (your documents)
â”œâ”€â”€ storage/                # Vector index (generated)
â”œâ”€â”€ data_images/            # Page images (generated, by doc_id)
â”œâ”€â”€ docs.md                 # LlamaIndex documentation reference
â”œâ”€â”€ Makefile                # Common commands
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ pytest.ini              # Test configuration
```

---

## Development

### Common Commands

```bash
make help               # Show all commands
make run                # Run Streamlit app
make api                # Run FastAPI server (development mode)
make api-prod           # Run FastAPI server (production mode with workers)
make parse              # Parse all PDFs (fresh index)
make add-batch          # Add PDFs to existing index
make test               # Run full test suite
make test-quick         # Fast tests (no coverage)
make clean              # Clean Python cache
make clean-storage      # Clear vector index
make format             # Format code (black + isort)
make lint               # Lint code (flake8 + mypy)
```

### Git Hook

Pre-commit hook runs tests automatically:

```bash
git commit -m "changes"  # Runs tests first
git commit --no-verify   # Skip tests (not recommended)

# Reinstall hook
./scripts/install-hooks.sh
```

---

## Testing

### Full Test Suite

```bash
make test               # Run all tests with coverage
make test-verbose       # Verbose output
make test-cov           # Coverage report (HTML + terminal)
make test-quick         # Fast (no coverage)
```

### Ingestion Module Tests

```bash
python scripts/test_ingestion.py
```

Tests all CRUD operations:
- âœ… Adding documents
- âœ… Listing documents
- âœ… Getting document info
- âœ… SOURCE relationship tracking
- âœ… Updating documents
- âœ… Deleting documents (index + images)

### Manual Testing (Python REPL)

```python
import asyncio
from src.ingestion import add_document, list_documents, delete_document

# Add a document
result = asyncio.run(add_document("data/manual.pdf"))
print(result)  # See document ID, page count

# List all
docs = list_documents()
print(f"Total documents: {len(docs)}")

# Delete
delete_document(result['document_id'])
```

### Validation Checklist

After running `make parse`, verify:

```bash
# 1. Check ref_doc_info is populated (SOURCE relationships work)
python3 -c "from src.ingestion import get_index; \
    print(f'Documents tracked: {len(get_index().ref_doc_info)}')"

# 2. Images exist in doc-specific directories
ls data_images/  # Should show UUID directories

# 3. Streamlit queries work
make run  # Test querying documents

# 4. Deletion works
python scripts/test_ingestion.py  # Run full test suite
```

**Success Criteria:**
- âœ… `ref_doc_info` shows tracked documents
- âœ… Images in `data_images/{doc_id}/` directories
- âœ… Streamlit finds and displays documents
- âœ… Test suite passes all tests
- âœ… Deletion removes index entries + images

---

## Tech Stack

- **Qdrant Cloud** - Managed vector database for embeddings and images
- **LlamaIndex** - RAG framework with document tracking
- **LlamaParse** - PDF parsing with multimodal extraction
- **OpenAI/Gemini** - LLM and embeddings
- **Streamlit** - Web UI for query interface
- **FastAPI** - REST API for document management
- **Uvicorn** - ASGI server for FastAPI
- **Pydantic** - Data validation and serialization
- **pytest** - Testing framework

---

## Next Steps

### Completed âœ…
- [x] Qdrant Cloud integration
- [x] Base64 image storage
- [x] Document tracking with SOURCE relationships
- [x] FastAPI REST API
- [x] Streamlit UI
- [x] Multi-worker support
- [x] CRUD operations

### Production Enhancements
- [ ] Monitoring & logging (Prometheus, Grafana)
- [ ] Authentication & authorization
- [ ] Rate limiting
- [ ] Caching layer (Redis)
- [ ] CI/CD pipeline
- [ ] Automated testing in pipeline

### Optional Improvements
- [ ] Migrate to S3 for images (if base64 becomes limiting)
- [ ] Add web scraping for non-PDF sources
- [ ] Implement semantic caching
- [ ] Add support for more document types (DOCX, HTML, etc.)

---

## Additional Documentation

- [`src/ingestion/README.md`](src/ingestion/README.md) - Detailed module API documentation
- [`docs.md`](docs.md) - LlamaIndex documentation reference and answers

---

## License

All rights reserved.
